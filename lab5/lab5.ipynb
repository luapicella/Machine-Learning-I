{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import scipy as sc\n",
    "\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0)\n",
    "    numpy.random.seed(seed)\n",
    "    idx = numpy.random.permutation(D.shape[1])\n",
    "    idxTrain = idx[0:nTrain]\n",
    "    idxTest = idx[nTrain:]\n",
    "    DTR = D[:, idxTrain]\n",
    "    DTE = D[:, idxTest]\n",
    "    LTR = L[idxTrain]\n",
    "    LTE = L[idxTest]\n",
    "    return (DTR, LTR), (DTE, LTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, L = load_iris()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcol(vector, shape0):\n",
    "    # Auxiliary function to transform 1-dim vectors to column vectors.\n",
    "    return vector.reshape(shape0, 1)\n",
    "\n",
    "\n",
    "def vrow(vector, shape1):\n",
    "    # Auxiliary function to transform 1-dim vecotrs to row vectors.\n",
    "    return vector.reshape(1, shape1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpdf_GAU_ND(x, mu, sigma):\n",
    "    return -(x.shape[0]/2)*numpy.log(2*numpy.pi)-(1/2)*(numpy.linalg.slogdet(sigma)[1])-(1/2)*((numpy.dot((x-mu).T, numpy.linalg.inv(sigma))).T*(x-mu)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScoreMatrix(D, mu0, sigma0, mu1, sigma1, mu2, sigma2, callback):\n",
    "    S = numpy.array([callback(D, mu0, sigma0), callback(\n",
    "        D, mu1, sigma1), callback(D, mu2, sigma2)])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMLestimates(D, L):\n",
    "    # Compute classes means over columns of the dataset matrix\n",
    "    mu0 = D[:, L == 0].mean(axis=1)\n",
    "    mu1 = D[:, L == 1].mean(axis=1)\n",
    "    mu2 = D[:, L == 2].mean(axis=1)\n",
    "    # Reshape all of them as 4x1 column vectors\n",
    "    mu0 = vcol(mu0, mu0.size)\n",
    "    mu1 = vcol(mu1, mu1.size)\n",
    "    mu2 = vcol(mu2, mu2.size)\n",
    "    # Count number of elements in each class\n",
    "    n0 = D[:, L == 0].shape[1]\n",
    "    n1 = D[:, L == 1].shape[1]\n",
    "    n2 = D[:, L == 2].shape[1]\n",
    "    # Subtract classes means from classes datasets with broadcasting\n",
    "    DC0 = D[:, L == 0]-mu0\n",
    "    DC1 = D[:, L == 1]-mu1\n",
    "    DC2 = D[:, L == 2]-mu2\n",
    "    # Compute classes covariance matrices\n",
    "    sigma0 = (1/n0)*(numpy.dot(DC0, DC0.T))\n",
    "    sigma1 = (1/n1)*(numpy.dot(DC1, DC1.T))\n",
    "    sigma2 = (1/n2)*(numpy.dot(DC2, DC2.T))\n",
    "    return (mu0, sigma0), (mu1, sigma1), (mu2, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariateGaussianClassifier(DTR, LTR, DEV, LEV):\n",
    "    # Compute estimates for model parameters (empirical mean\n",
    "    # and covariance matrix of each class). This is the training phase.\n",
    "    (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "    # Now we have the estimated model parameters and we can turn our attention towards\n",
    "    # inference for a test sample x of the evaluation set. The final goal is to\n",
    "    # compute class posterior probabilities, but we split the process in three stages.\n",
    "\n",
    "    # 1) Compute, for each test sample, the MVG log-density.\n",
    "    # We can proceed as seen in lab 04 and we can store class-conditional\n",
    "    # probabilities (the computed log-densities) in a score matrix logS. logS[i, j]\n",
    "    # should be the class conditional probability for sample j given class i.\n",
    "    logS = computeScoreMatrix(DTE, mu0, sigma0, mu1,\n",
    "                          sigma1, mu2, sigma2, logpdf_GAU_ND)\n",
    "    # 2) Compute the matrix of joint log-distribution probabilities logSJoint for\n",
    "    # samples and classes combining the score matrix with prior information.\n",
    "    # We assume that the three classes have the same\n",
    "    # prior probability P(c) = 1/3. logSJoints requires adding each row of\n",
    "    # logS to the logarithm of the prior probability of the corresponding class.\n",
    "    priorLogProbabilities = vcol(\n",
    "        numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "    logSJoint = logS+priorLogProbabilities  # 3x50\n",
    "    # 3) We can finally compute class posterior probabilities. But we need to compute\n",
    "    # the marginal log-density. We can use scipy.special.logsumexp(logSJoint, axis=0)\n",
    "    marginalLogDensities = vrow(\n",
    "        sc.special.logsumexp(logSJoint, axis=0), 50)  # 1x50\n",
    "    # Now we can compute the array of class log-posterior probabilities logSPost.\n",
    "    logSPost = logSJoint-marginalLogDensities\n",
    "    # The predicted label is obtained as the class that has maximum posterior\n",
    "    # probability, in our 3x50 logSPost matrix. This needs to be done for each sample.\n",
    "    # We can use argmax with axis=0 on the logSPost matrix. It will return an\n",
    "    # array whose values are the indices (in our case 0, 1, 2) of the maximum\n",
    "    # values along the specified axis. (So, for us is the maximum of each column)\n",
    "    predictedLabels = logSPost.argmax(axis=0)\n",
    "    # We can now compute an array of booleans corresponding to whether predicted\n",
    "    # and real labels are equal or not. Then, summing all the elements of a\n",
    "    # boolean array gives the number of elements that are True.\n",
    "    numberOfCorrectPredictions = numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/LEV.size*100\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"Accuracy of the MVG classifier when working with log-densities: %.2f %%\" % (accuracy))\n",
    "    print(\"Error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesGaussianClassifier(DTR, LTR, DEV, LEV):\n",
    "    # Compute estimates for model parameters (empirical mean\n",
    "    # and covariance matrix of each class). This is the training phase.\n",
    "    (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "    # But for the Naive Bayes version of MVG the covariance matrices are diagonal!\n",
    "    # The ML solution for the mean parameters is the same, while the ML solution\n",
    "    # for the covariance matrices is different. Since the number of feature is\n",
    "    # small, we can adapt the MVG code by simply zeroing the out-of-diagonal\n",
    "    # elements of the MVG ML solution, keeping them as matrices. This can be\n",
    "    # done, for example, multiplying element-wise the MVG ML solution with the\n",
    "    # identity matrix. The rest of the code is the same as MVGlogdensities.\n",
    "    # This procedure (keeping the matrix, etc.) is not advisable when we work\n",
    "    # on large dimensional data, in those cases it may be better to implement\n",
    "    # ad-hoc functions to work directly with just the diagonal of the covariance\n",
    "    # matrices.\n",
    "    (sigma0, sigma1, sigma2) = (sigma0*numpy.identity(sigma0.shape[0]), sigma1*numpy.identity(\n",
    "        sigma1.shape[0]), sigma2*numpy.identity(sigma2.shape[0]))\n",
    "    # Now we have the estimated model parameters and we can turn our attention towards\n",
    "    # inference for a test sample x of the evaluation set. The final goal is to\n",
    "    # compute class posterior probabilities, but we split the process in three stages.\n",
    "\n",
    "    # 1) Compute, for each test sample, the MVG log-density.\n",
    "    # We can proceed as seen in lab 04 and we can store class-conditional\n",
    "    # probabilities (the computed log-densities) in a score matrix logS. logS[i, j]\n",
    "    # should be the class conditional probability for sample j given class i.\n",
    "    logS = computeScoreMatrix(DTE, mu0, sigma0, mu1,\n",
    "                          sigma1, mu2, sigma2, logpdf_GAU_ND)\n",
    "    # 2) Compute the matrix of joint log-distribution probabilities logSJoint for\n",
    "    # samples and classes combining the score matrix with prior information.\n",
    "    # We assume that the three classes have the same\n",
    "    # prior probability P(c) = 1/3. logSJoints requires adding each row of\n",
    "    # logS to the logarithm of the prior probability of the corresponding class.\n",
    "    priorLogProbabilities = vcol(\n",
    "        numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "    logSJoint = logS+priorLogProbabilities  # 3x50\n",
    "    # 3) We can finally compute class posterior probabilities. But we need to compute\n",
    "    # the marginal log-density. We can use scipy.special.logsumexp(logSJoint, axis=0)\n",
    "    marginalLogDensities = vrow(\n",
    "        sc.special.logsumexp(logSJoint, axis=0), 50)  # 1x50\n",
    "    # Now we can compute the array of class log-posterior probabilities logSPost.\n",
    "    logSPost = logSJoint-marginalLogDensities\n",
    "    # The predicted label is obtained as the class that has maximum posterior\n",
    "    # probability, in our 3x50 logSPost matrix. This needs to be done for each sample.\n",
    "    # We can use argmax with axis=0 on the logSPost matrix. It will return an\n",
    "    # array whose values are the indices (in our case 0, 1, 2) of the maximum\n",
    "    # values along the specified axis. (So, for us is the maximum of each column)\n",
    "    predictedLabels = logSPost.argmax(axis=0)\n",
    "    # We can now compute an array of booleans corresponding to whether predicted\n",
    "    # and real labels are equal or not. Then, summing all the elements of a\n",
    "    # boolean array gives the number of elements that are True.\n",
    "    numberOfCorrectPredictions = numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/LEV.size*100\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"Accuracy of the naive bayes MVG classifier when working with log-densities: %.2f %%\" % (accuracy))\n",
    "    print(\"Error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiedGaussianClassifier(DTR, LTR, DEV, LEV):\n",
    "    # Compute estimates for model parameters (empirical mean\n",
    "    # and covariance matrix of each class). This is the training phase.\n",
    "    (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "    # But for the tied covariance version of the classifier the class covariance\n",
    "    # matrices are tied, this mean that sigmai=sigma, they're all the same.\n",
    "    # We have seen that the ML solution for the class means is again the same.\n",
    "    # The ML solution for the covariance matrix, instead, is given by the empirical\n",
    "    # within-class covariance matrix. We already computed it when we implemented\n",
    "    # LDA, alternatively (and I will do so in the following) we can compute it\n",
    "    # from the covariance matrices sigma0, sigma1 and sigma2:\n",
    "    sigma = (1/DTR.shape[1])*((LTR == 0).sum()*sigma0 +\n",
    "                              (LTR == 1).sum()*sigma1+(LTR == 2).sum()*sigma2)\n",
    "    # Now we have the estimated model parameters and we can turn our attention towards\n",
    "    # inference for a test sample x of the evaluation set. The final goal is to\n",
    "    # compute class posterior probabilities, but we split the process in three stages.\n",
    "\n",
    "    # 1) Compute, for each test sample, the MVG log-density.\n",
    "    # We can proceed as seen in lab 04 and we can store class-conditional\n",
    "    # probabilities (the computed log-densities) in a score matrix logS. logS[i, j]\n",
    "    # should be the class conditional probability for sample j given class i.\n",
    "    logS = computeScoreMatrix(DTE, mu0, sigma, mu1,\n",
    "                          sigma, mu2, sigma, logpdf_GAU_ND)\n",
    "    # 2) Compute the matrix of joint log-distribution probabilities logSJoint for\n",
    "    # samples and classes combining the score matrix with prior information.\n",
    "    # We assume that the three classes have the same\n",
    "    # prior probability P(c) = 1/3. logSJoints requires adding each row of\n",
    "    # logS to the logarithm of the prior probability of the corresponding class.\n",
    "    priorLogProbabilities = vcol(\n",
    "        numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "    logSJoint = logS+priorLogProbabilities  # 3x50\n",
    "    # 3) We can finally compute class posterior probabilities. But we need to compute\n",
    "    # the marginal log-density. We can use scipy.special.logsumexp(logSJoint, axis=0)\n",
    "    marginalLogDensities = vrow(\n",
    "        sc.special.logsumexp(logSJoint, axis=0), 50)  # 1x50\n",
    "    # Now we can compute the array of class log-posterior probabilities logSPost.\n",
    "    logSPost = logSJoint-marginalLogDensities\n",
    "    # The predicted label is obtained as the class that has maximum posterior\n",
    "    # probability, in our 3x50 logSPost matrix. This needs to be done for each sample.\n",
    "    # We can use argmax with axis=0 on the logSPost matrix. It will return an\n",
    "    # array whose values are the indices (in our case 0, 1, 2) of the maximum\n",
    "    # values along the specified axis. (So, for us is the maximum of each column)\n",
    "    predictedLabels = logSPost.argmax(axis=0)\n",
    "    # We can now compute an array of booleans corresponding to whether predicted\n",
    "    # and real labels are equal or not. Then, summing all the elements of a\n",
    "    # boolean array gives the number of elements that are True.\n",
    "    numberOfCorrectPredictions = numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/LEV.size*100\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"Accuracy of the tied MVG classifier when working with log-densities: %.2f %%\" % (accuracy))\n",
    "    print(\"Error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MVG classifier when working with log-densities: 96.00 %\n",
      "Error rate: 4.00 %\n",
      "Accuracy of the naive bayes MVG classifier when working with log-densities: 96.00 %\n",
      "Error rate: 4.00 %\n",
      "Accuracy of the tied MVG classifier when working with log-densities: 98.00 %\n",
      "Error rate: 2.00 %\n"
     ]
    }
   ],
   "source": [
    "multivariateGaussianClassifier(DTR, LTR, DTE, LTE)\n",
    "naiveBayesGaussianClassifier(DTR, LTR, DTE, LTE)\n",
    "tiedGaussianClassifier(DTR, LTR, DTE, LTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold approch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldCrossValidationMVG(D, L):\n",
    "    # Same procedure of MVGlogdensities but with leave-one-out approach:\n",
    "    # number of folds is equal to the number of samples, we iterate over all samples\n",
    "    # and each time we use one of them as evaluation set and the remaining 149\n",
    "    # as training set.\n",
    "    # Then we compute the predicted lable and count how many times it is correct.\n",
    "    numberOfCorrectPredictions = 0\n",
    "    for i in range(D.shape[1]):  # i=0...149\n",
    "        # Each time we need to delete the i-th column (sample) from the training set\n",
    "        # while in the evaluation set we should keep only the i-th column.\n",
    "        # vcol is necessary to exploit broadcasting\n",
    "        (DTR, LTR), (DEV, LEV) = (numpy.delete(D, i, 1),\n",
    "                                  numpy.delete(L, i)), (vcol(D[:, i], 4), L[i])\n",
    "        (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "        logS = computeScoreMatrix(DEV, mu0, sigma0, mu1,\n",
    "                                  sigma1, mu2, sigma2, logpdf_GAU_ND)\n",
    "        priorLogProbabilities = vcol(\n",
    "            numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "        logSJoint = logS+priorLogProbabilities  # 3x1\n",
    "        marginalLogDensities = vrow(\n",
    "            sc.special.logsumexp(logSJoint, axis=0), 1)  # 1x1\n",
    "        # We need to keep it as 1x1 to exploit broadcasting\n",
    "        logSPost = logSJoint-marginalLogDensities\n",
    "        predictedLabels = logSPost.argmax(axis=0)\n",
    "        # Add the result of prediction to the proper variable\n",
    "        numberOfCorrectPredictions += numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/L.size * \\\n",
    "        100  # over all samples, that are 150\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"MVG classifier: accuracy : %.2f %%\" % (accuracy))\n",
    "    print(\"MVG classifier: error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldCrossValidationNaiveBayesMVG(D, L):\n",
    "    # Same procedure of MVGlogdensities but with leave-one-out approach:\n",
    "    # number of folds is equal to the number of samples, we iterate over all samples\n",
    "    # and each time we use one of them as evaluation set and the remaining 149\n",
    "    # as training set.\n",
    "    # Then we compute the predicted lable and count how many times it is correct.\n",
    "    numberOfCorrectPredictions = 0\n",
    "    for i in range(D.shape[1]):  # i=0...149\n",
    "        # Each time we need to delete the i-th column (sample) from the training set\n",
    "        # while in the evaluation set we should keep only the i-th column.\n",
    "        # vcol is necessary to exploit broadcasting\n",
    "        (DTR, LTR), (DEV, LEV) = (numpy.delete(D, i, 1),\n",
    "                                  numpy.delete(L, i)), (vcol(D[:, i], 4), L[i])\n",
    "        (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "        (sigma0, sigma1, sigma2) = (sigma0*numpy.identity(sigma0.shape[0]), sigma1*numpy.identity(\n",
    "        sigma1.shape[0]), sigma2*numpy.identity(sigma2.shape[0]))\n",
    "        logS = computeScoreMatrix(DEV, mu0, sigma0, mu1,\n",
    "                                  sigma1, mu2, sigma2, logpdf_GAU_ND)\n",
    "        priorLogProbabilities = vcol(\n",
    "            numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "        logSJoint = logS+priorLogProbabilities  # 3x1\n",
    "        marginalLogDensities = vrow(\n",
    "            sc.special.logsumexp(logSJoint, axis=0), 1)  # 1x1\n",
    "        # We need to keep it as 1x1 to exploit broadcasting\n",
    "        logSPost = logSJoint-marginalLogDensities\n",
    "        predictedLabels = logSPost.argmax(axis=0)\n",
    "        # Add the result of prediction to the proper variable\n",
    "        numberOfCorrectPredictions += numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/L.size * \\\n",
    "        100  # over all samples, that are 150\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"MVG naive classifier: accuracy : %.2f %%\" % (accuracy))\n",
    "    print(\"MVG naive classifier: error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldCrossValidationTiedMVG(D, L):\n",
    "    # Same procedure of MVGlogdensities but with leave-one-out approach:\n",
    "    # number of folds is equal to the number of samples, we iterate over all samples\n",
    "    # and each time we use one of them as evaluation set and the remaining 149\n",
    "    # as training set.\n",
    "    # Then we compute the predicted lable and count how many times it is correct.\n",
    "    numberOfCorrectPredictions = 0\n",
    "    for i in range(D.shape[1]):  # i=0...149\n",
    "        # Each time we need to delete the i-th column (sample) from the training set\n",
    "        # while in the evaluation set we should keep only the i-th column.\n",
    "        # vcol is necessary to exploit broadcasting\n",
    "        (DTR, LTR), (DEV, LEV) = (numpy.delete(D, i, 1),\n",
    "                                  numpy.delete(L, i)), (vcol(D[:, i], 4), L[i])\n",
    "        (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "        sigma = (1/DTR.shape[1])*((LTR == 0).sum()*sigma0 +\n",
    "                              (LTR == 1).sum()*sigma1+(LTR == 2).sum()*sigma2)\n",
    "        logS = computeScoreMatrix(DEV, mu0, sigma, mu1,\n",
    "                                  sigma, mu2, sigma, logpdf_GAU_ND)\n",
    "        priorLogProbabilities = vcol(\n",
    "            numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "        logSJoint = logS+priorLogProbabilities  # 3x1\n",
    "        marginalLogDensities = vrow(\n",
    "            sc.special.logsumexp(logSJoint, axis=0), 1)  # 1x1\n",
    "        # We need to keep it as 1x1 to exploit broadcasting\n",
    "        logSPost = logSJoint-marginalLogDensities\n",
    "        predictedLabels = logSPost.argmax(axis=0)\n",
    "        # Add the result of prediction to the proper variable\n",
    "        numberOfCorrectPredictions += numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/L.size * \\\n",
    "        100  # over all samples, that are 150\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"MVG tied classifier: accuracy : %.2f %%\" % (accuracy))\n",
    "    print(\"MVG tied classifier: error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldCrossValidationTiedNaiveBayesMVG(D, L):\n",
    "    # Same procedure of MVGlogdensities but with leave-one-out approach:\n",
    "    # number of folds is equal to the number of samples, we iterate over all samples\n",
    "    # and each time we use one of them as evaluation set and the remaining 149\n",
    "    # as training set.\n",
    "    # Then we compute the predicted lable and count how many times it is correct.\n",
    "    numberOfCorrectPredictions = 0\n",
    "    for i in range(D.shape[1]):  # i=0...149\n",
    "        # Each time we need to delete the i-th column (sample) from the training set\n",
    "        # while in the evaluation set we should keep only the i-th column.\n",
    "        # vcol is necessary to exploit broadcasting\n",
    "        (DTR, LTR), (DEV, LEV) = (numpy.delete(D, i, 1),\n",
    "                                  numpy.delete(L, i)), (vcol(D[:, i], 4), L[i])\n",
    "        (mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)\n",
    "        sigma = (1/DTR.shape[1])*((LTR == 0).sum()*sigma0 +\n",
    "                              (LTR == 1).sum()*sigma1+(LTR == 2).sum()*sigma2)\n",
    "        sigma = sigma*numpy.identity(sigma.shape[0])\n",
    "        logS = computeScoreMatrix(DEV, mu0, sigma, mu1,\n",
    "                                  sigma, mu2, sigma, logpdf_GAU_ND)\n",
    "        priorLogProbabilities = vcol(\n",
    "            numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "        logSJoint = logS+priorLogProbabilities  # 3x1\n",
    "        marginalLogDensities = vrow(\n",
    "            sc.special.logsumexp(logSJoint, axis=0), 1)  # 1x1\n",
    "        # We need to keep it as 1x1 to exploit broadcasting\n",
    "        logSPost = logSJoint-marginalLogDensities\n",
    "        predictedLabels = logSPost.argmax(axis=0)\n",
    "        # Add the result of prediction to the proper variable\n",
    "        numberOfCorrectPredictions += numpy.array(predictedLabels == LEV).sum()\n",
    "    # Now we can compute percentage values for accuracy and error rate.\n",
    "    accuracy = numberOfCorrectPredictions/L.size * \\\n",
    "        100  # over all samples, that are 150\n",
    "    errorRate = 100-accuracy\n",
    "    print(\"MVG tied naive classifier: accuracy : %.2f %%\" % (accuracy))\n",
    "    print(\"MVG tied naive classifier: error rate: %.2f %%\" % (errorRate))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVG classifier: accuracy : 97.33 %\n",
      "MVG classifier: error rate: 2.67 %\n",
      "MVG naive classifier: accuracy : 95.33 %\n",
      "MVG naive classifier: error rate: 4.67 %\n",
      "MVG tied classifier: accuracy : 98.00 %\n",
      "MVG tied classifier: error rate: 2.00 %\n",
      "MVG tied naive classifier: accuracy : 96.00 %\n",
      "MVG tied naive classifier: error rate: 4.00 %\n"
     ]
    }
   ],
   "source": [
    "kfoldCrossValidationMVG(D, L)\n",
    "kfoldCrossValidationNaiveBayesMVG(D, L)\n",
    "kfoldCrossValidationTiedMVG(D, L)\n",
    "kfoldCrossValidationTiedNaiveBayesMVG(D, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "idx = numpy.random.permutation(2)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9, 5.1],\n",
       "       [3. , 3.5],\n",
       "       [1.4, 1.4],\n",
       "       [0.2, 0.2]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3\n",
    "i = 0\n",
    "n_sample_fold = int(2)\n",
    "#D[:,idx[(i*n_sample_fold): ((i+1)*(n_sample_fold))]]\n",
    "D[:, idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_sizes = numpy.full(4, 11 // 4, dtype=int)\n",
    "fold_sizes[: 11 % 4] \n",
    "#fold_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.asarray(L)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_idx, y_inv = np.unique(y, return_index=True, return_inverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  50, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, class_perm = np.unique(y_idx, return_inverse=True)\n",
    "class_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = class_perm[y_inv]\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 50, 50])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(y_idx)\n",
    "y_counts = np.bincount(y_encoded)\n",
    "y_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_groups = np.min(y_counts)\n",
    "min_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_order = np.sort(y_encoded)\n",
    "allocation = np.asarray(\n",
    "    [\n",
    "        np.bincount(y_order[i :: 3], minlength=n_classes)\n",
    "        for i in range(3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_order[i :: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds = np.empty(len(y), dtype=\"i\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    # since the kth column of allocation stores the number of samples\n",
    "    # of class k in each test set, this generates blocks of fold\n",
    "    # indices corresponding to the allocation for class k.\n",
    "    folds_for_class = np.arange(3).repeat(allocation[:, k])\n",
    "    test_folds[y_encoded == k] = folds_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_for_class = np.arange(3).repeat(allocation[:, 1])\n",
    "folds_for_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folds[y_encoded == k] = folds_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20077b7d1bf57ab26971ff2f0fd3e9d3bdb941da4b07257f74cc5c118759c9ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
