{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0)\n",
    "    numpy.random.seed(seed)\n",
    "    idx = numpy.random.permutation(D.shape[1])\n",
    "    idxTrain = idx[0:nTrain]\n",
    "    idxTest = idx[nTrain:]\n",
    "    DTR = D[:, idxTrain]\n",
    "    DTE = D[:, idxTest]\n",
    "    LTR = L[idxTrain]\n",
    "    LTE = L[idxTest]\n",
    "    return (DTR, LTR), (DTE, LTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, L = load_iris()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcol(vector, shape0):\n",
    "    # Auxiliary function to transform 1-dim vectors to column vectors.\n",
    "    return vector.reshape(shape0, 1)\n",
    "\n",
    "\n",
    "def vrow(vector, shape1):\n",
    "    # Auxiliary function to transform 1-dim vecotrs to row vectors.\n",
    "    return vector.reshape(1, shape1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMLestimates(D, L):\n",
    "    # Compute classes means over columns of the dataset matrix\n",
    "    mu0 = D[:, L == 0].mean(axis=1)\n",
    "    mu1 = D[:, L == 1].mean(axis=1)\n",
    "    mu2 = D[:, L == 2].mean(axis=1)\n",
    "    # Reshape all of them as 4x1 column vectors\n",
    "    mu0 = vcol(mu0, mu0.size)\n",
    "    mu1 = vcol(mu1, mu1.size)\n",
    "    mu2 = vcol(mu2, mu2.size)\n",
    "    # Count number of elements in each class\n",
    "    n0 = D[:, L == 0].shape[1]\n",
    "    n1 = D[:, L == 1].shape[1]\n",
    "    n2 = D[:, L == 2].shape[1]\n",
    "    # Subtract classes means from classes datasets with broadcasting\n",
    "    DC0 = D[:, L == 0]-mu0\n",
    "    DC1 = D[:, L == 1]-mu1\n",
    "    DC2 = D[:, L == 2]-mu2\n",
    "    # Compute classes covariance matrices\n",
    "    sigma0 = (1/n0)*(numpy.dot(DC0, DC0.T))\n",
    "    sigma1 = (1/n1)*(numpy.dot(DC1, DC1.T))\n",
    "    sigma2 = (1/n2)*(numpy.dot(DC2, DC2.T))\n",
    "    return (mu0, sigma0), (mu1, sigma1), (mu2, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n0 = DTR[:, LTR == 0].shape[1]\n",
    "n0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mu0, sigma0), (mu1, sigma1), (mu2, sigma2) = computeMLestimates(DTR, LTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScoreMatrix(D, mu0, sigma0, mu1, sigma1, mu2, sigma2, callback):\n",
    "    S = numpy.array([callback(D, mu0, sigma0), callback(\n",
    "        D, mu1, sigma1), callback(D, mu2, sigma2)])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpdf_GAU_ND(x, mu, sigma):\n",
    "    return -(x.shape[0]/2)*numpy.log(2*numpy.pi)-(1/2)*(numpy.linalg.slogdet(sigma)[1])-(1/2)*((numpy.dot((x-mu).T, numpy.linalg.inv(sigma))).T*(x-mu)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute, for each test sample, the MVG log-density.\n",
    "# We can proceed as seen in lab 04 and we can store class-conditional\n",
    "# probabilities (the computed log-densities) in a score matrix logS. logS[i, j]\n",
    "# should be the class conditional probability for sample j given class i.\n",
    "logS = computeScoreMatrix(DTE, mu0, sigma0, mu1,\n",
    "                          sigma1, mu2, sigma2, logpdf_GAU_ND)\n",
    "logS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Compute the matrix of joint log-distribution probabilities logSJoint for\n",
    "# samples and classes combining the score matrix with prior information.\n",
    "# We assume that the three classes have the same\n",
    "# prior probability P(c) = 1/3. logSJoints requires adding each row of\n",
    "# logS to the logarithm of the prior probability of the corresponding class.\n",
    "priorLogProbabilities = vcol(numpy.array([numpy.log(1/3), numpy.log(1/3), numpy.log(1/3)]), 3)\n",
    "logSJoint = logS + priorLogProbabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priorLogProbabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "marginalLogDensities = vrow(sc.special.logsumexp(logSJoint, axis=0), 50)  # 1x50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compute the array of class log-posterior probabilities logSPost.\n",
    "logSPost = logSJoint - marginalLogDensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  [0 0 1 2 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 2 1 0 1 2\n",
      " 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# The predicted label is obtained as the class that has maximum posterior\n",
    "# probability, in our 3x50 logSPost matrix. This needs to be done for each sample.\n",
    "# We can use argmax with axis=0 on the logSPost matrix. It will return an\n",
    "# array whose values are the indices (in our case 0, 1, 2) of the maximum\n",
    "# values along the specified axis. (So, for us is the maximum of each column)\n",
    "predictedLabels = logSPost.argmax(axis=0)\n",
    "print(\"Predicted labels: \", predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now compute an array of booleans corresponding to whether predicted\n",
    "# and real labels are equal or not. Then, summing all the elements of a\n",
    "# boolean array gives the number of elements that are True.\n",
    "numberOfCorrectPredictions = numpy.array(predictedLabels == LTE).sum()\n",
    "# Now we can compute percentage values for accuracy and error rate.\n",
    "accuracy = numberOfCorrectPredictions/LTE.size*100\n",
    "errorRate = 100-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 96.0\n",
      "errorRate is: 4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy is:\",accuracy)\n",
    "print(f\"errorRate is:\",errorRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test wih the solution\n",
    "solutionLogMariginal = numpy.load('./solution/logPosterior_MVG.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.unique(L).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 3\n",
    "my_array = numpy.zeros((3,10))\n",
    "for i in range(3):\n",
    "    #for 1D array\n",
    "    my_array[i] = numpy.array([1,2,3,4,5,6,7,8,9,10])\n",
    "my_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20077b7d1bf57ab26971ff2f0fd3e9d3bdb941da4b07257f74cc5c118759c9ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
